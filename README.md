# ğŸšŒ AnÃ¡lise de Dados dos Ã”nibus do Rio de Janeiro

Este repositÃ³rio contÃ©m uma **pipeline completa em Python** para **coletar, processar e analisar dados de performance dos Ã´nibus** da cidade do **Rio de Janeiro**, utilizando informaÃ§Ãµes pÃºblicas da **API Data.Rio (SPPO)** e **feeds GTFS**.

---

## ğŸ“ Estrutura do RepositÃ³rio

A organizaÃ§Ã£o segue uma arquitetura modular, separando claramente as etapas da pipeline de dados:

```
.
â”œâ”€â”€ gtfs/           # Arquivos estÃ¡ticos do feed GTFS (routes.txt, stops.txt, etc.)
â”œâ”€â”€ data_inputs/    # Arquivos manuais ou auxiliares (ex: mapeamentos, equivalÃªncias de linhas)
â”œâ”€â”€ src/            # CÃ³digo-fonte principal da pipeline ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga)
â”œâ”€â”€ analysis/       # Scripts de anÃ¡lise exploratÃ³ria e geraÃ§Ã£o de relatÃ³rios
â”œâ”€â”€ reports/        # RelatÃ³rios finais gerados apÃ³s a anÃ¡lise (ex: analise_viagens.txt)
â””â”€â”€ tools/          # Scripts utilitÃ¡rios para verificaÃ§Ã£o e monitoramento dos dados brutos
```

---

## âš™ï¸ Requisitos e InstalaÃ§Ã£o

### ğŸ PrÃ©-requisitos

* Python 3.8 ou superior
* Acesso Ã  API, caso queira apenas usar o codigo para extrair a API

### ğŸ“¦ InstalaÃ§Ã£o das DependÃªncias

Instale todas as bibliotecas necessÃ¡rias com um Ãºnico comando:

```bash
pip install pandas numpy openpyxl geopy tqdm ijson
```

---

## ğŸ“š Bibliotecas Utilizadas

| Biblioteca   | FunÃ§Ã£o Principal                                           |
| ------------ | ---------------------------------------------------------- |
| **pandas**   | ManipulaÃ§Ã£o e processamento de dados tabulares (GTFS, CSV) |
| **numpy**    | CÃ¡lculos estatÃ­sticos e numÃ©ricos (anÃ¡lise de performance) |
| **openpyxl** | Leitura e escrita de planilhas `.xlsx` pelo pandas         |
| **geopy**    | CÃ¡lculo de distÃ¢ncias geogrÃ¡ficas (great-circle)           |
| **tqdm**     | ExibiÃ§Ã£o de barras de progresso durante o processamento    |
| **ijson**    | Leitura eficiente de grandes arquivos JSON em streaming    |

---

## ğŸ”„ Pipeline de Dados (ETL)

A pipeline Ã© composta por scripts numerados localizados em `/src/`, representando as etapas clÃ¡ssicas de **ExtraÃ§Ã£o**, **TransformaÃ§Ã£o** e **Carga**:

1. **ExtraÃ§Ã£o**
   Coleta dados do feed GTFS e da API SPPO.

2. **TransformaÃ§Ã£o**
   Processa, filtra e cruza as informaÃ§Ãµes das viagens e veÃ­culos.

3. **Carga**
   Gera o arquivo consolidado `viagens.csv` com os dados limpos e prontos para anÃ¡lise.

---

## ğŸ“Š AnÃ¡lise de Performance

ApÃ³s a execuÃ§Ã£o completa da pipeline, o arquivo final `viagens.csv` Ã© gerado na pasta raiz ou em `/data_outputs/`.

### â–¶ï¸ ExecuÃ§Ã£o da AnÃ¡lise

Use o script principal da pasta `analysis/`:

```bash
python analysis/analisar_performance_viagens.py
```

### ğŸ” O que ele faz

* LÃª o arquivo `viagens.csv`
* Aplica filtros estatÃ­sticos (como **IQR** para outliers)
* Calcula mÃ©tricas de desempenho por linha, empresa e horÃ¡rio
* Gera um relatÃ³rio detalhado de performance

### ğŸ“ SaÃ­da

O resultado Ã© salvo em:

```
reports/analise_viagens.txt
```

---

## ğŸ§° Ferramentas Auxiliares

A pasta `/tools/` contÃ©m utilitÃ¡rios de suporte, como:

* `verificar_dados_sppo.py`: Verifica a integridade e consistÃªncia dos dados brutos obtidos da API SPPO.
* Scripts adicionais para depuraÃ§Ã£o e monitoramento dos feeds GTFS.

---

## ğŸš€ PrÃ³ximos Passos

* Implementar visualizaÃ§Ãµes grÃ¡ficas com **Matplotlib** ou **Plotly**
* Automatizar a atualizaÃ§Ã£o dos dados via **cron job**
* Publicar dashboards no **Data Studio** ou **Power BI**

---

## ğŸ™ï¸ Fontes dos Dados

* API Data.Rio â€“ SPPO
* Feed GTFS â€“ Mobilidade Urbana RJ

---
